Run 2025-09-20T155229Z — full baseline, warm-start from best; objective: recover/raise reward while keeping collisions low.

Effective config (from config.json):
- Device: mps; optimizer: muon; anneal_lr: true; torch_deterministic: true
- PPO: lr 0.0025, ent_coef 0.02, bptt 16, update_epochs 20, clip_coef 0.15, vf_coef 2.0, vf_clip_coef 1.0, max_grad_norm 1.5
- Topology: vec 28/56; env 4×8 (env.num_envs × num_drones)
- Derived batch: 4 × 8 × 56 × 16 = 28,672 (minibatch = max_minibatch = 28,672)
- Divisibility: 56 % 28 == 0 (OK)
- Resume: continue from best (autopilot injected load_model_path)

Outcome (trainer_summary.json):
- success_rate: 512.387 (env-specific scale)
- mean_reward: 479.786; collision_rate: 0.003460; episode_length: 875.019
- Throughput: SPS 123,910; agent_steps 20.93M; epoch 698

TUI observations (end of run snapshot):
- explained_variance ≈ 0.837; policy_loss ≈ 0.023; value_loss ≈ 0.003; approx_kl ~ 0.0; clipfrac ~ 0.0
- Utilization: CPU ~311–326%; GPU 0%; VRAM 0%; DRAM ~34% (CPU‑bound with headroom, MPS not a bottleneck)

Comparison to recent runs:
- 2025-09-20T152244Z (best): mean_reward 535.245; collision_rate 0.003434; SPS 128,243
- 2025-09-20T154105Z (aggressive exploration: lr 0.003, ent_coef 0.1): mean_reward −4.949; collision_rate 0.000454; SPS 119,579
- Current run recovers from the failed high‑entropy attempt but remains ~10.3% below the earlier best reward; collisions stay comparably low.

Theory:
- Raising entropy to 0.02 likely reintroduced too much exploration relative to the strong warm‑start, pulling policy off‑manifold and lowering reward. Persistently near‑zero clipfrac suggests PPO updates are conservative; with high explained_variance and small policy/value losses, fewer epochs and a slightly tighter clip may stabilize updates while returning entropy to 0.01 should cut exploration noise.

Next iteration (saved to proposals/next_config.json):
- ent_coef: 0.01; update_epochs: 12; clip_coef: 0.12; max_grad_norm: 1.0
- Resume policy: continue from best; save_strategy: best
- Keep topology (vec 28/56; env 4×8) and lr 0.0025 for reproducibility

What to watch:
- Target mean_reward ≥ 535 with collision_rate ≤ 0.0035 and similar SPS
- If clipfrac remains ≈0 and reward stalls, consider increasing clip_coef to 0.18–0.20 or lowering vf_coef to 1.5 to emphasize policy improvement; optimizer switch to adamw is a backup option.

diff --git a/PufferLib/pufferlib/ocean/drone_pp/drone_pp.h b/PufferLib/pufferlib/ocean/drone_pp/drone_pp.h
index 43e92d1..18e0292 100644
--- a/PufferLib/pufferlib/ocean/drone_pp/drone_pp.h
+++ b/PufferLib/pufferlib/ocean/drone_pp/drone_pp.h
@@ -483,17 +483,18 @@ float compute_reward(DronePP* env, Drone *agent, bool collision) {
                         collision_penalty;
 
     // Mild boundary proximity penalty (XY only) to reduce OOB without adding
-    // soft walls or centralizing forces. Penalize only when an agent roams
-    // outside the inner 80% of the arena, scaling up to the hard boundary.
-    // This preserves clean physics while discouraging far‑field runaways
-    // observed in recent runs (OOB ≈ 0.82–0.84).
+    // soft walls or centralizing forces. Start discouraging drift when agents
+    // leave the inner 55% of the arena (was 60%), scaling up smoothly to the
+    // hard boundary. Slightly earlier onset + stronger weight target the
+    // persistent far‑field runaways observed (OOB ≈ 0.81 at epoch 85).
     float frac_x = fabsf(agent->state.pos.x) / GRID_X;
     float frac_y = fabsf(agent->state.pos.y) / GRID_Y;
-    float over_x = fmaxf(0.0f, frac_x - 0.8f) / 0.2f;
-    float over_y = fmaxf(0.0f, frac_y - 0.8f) / 0.2f;
+    float over_x = fmaxf(0.0f, frac_x - 0.55f) / 0.45f;
+    float over_y = fmaxf(0.0f, frac_y - 0.55f) / 0.45f;
     float boundary_prox = fminf(1.0f, fmaxf(over_x, over_y));
-    // Small fixed weight so no config change needed
-    total_reward -= 0.15f * boundary_prox;
+    // Slightly stronger weight to meaningfully counter long XY drifts
+    // without dominating shaped rewards.
+    total_reward -= 0.25f * boundary_prox;
 
     total_reward = clampf(total_reward, -1.0f, 1.0f);
 

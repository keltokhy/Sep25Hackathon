OVERVIEW & GOALS
- Use behavioral analysis to improve the drone pick‑and‑place task (grip → carry → deliver) by changing environment code, not hyperparameters.
- Honor a strict no‑hyperparameter‑changes policy. Treat `autopilot/journal/notes.md` as long‑term memory and constraints.

OPERATING PRINCIPLES (Thoughtful, Memory‑Driven)
- Read `autopilot/journal/notes.md` before acting; specifically consult the section “Header evolution: `drone_pp.h` (Sep 11 → Sep 20, 2025)” for historical intent and guardrails. Mirror key learnings to `autopilot/journal/labbook.md` after each run.
- For non‑trivial work, write a brief 2–4 step plan, then execute and verify against constraints (divisibility, batch math).
- Always state the behavioral hypothesis you are testing and the expected effect on grip/hover/carry/deliver metrics.
- If guidance conflicts, prefer the latest committed environment code and the Notes file.

WORKFLOW (Numbered Core Loop)
1) Execute {script} (autopilot/scripts/run_training.sh) with ≥15‑minute timeout. Do not skip.
2) Read the fresh run’s `trainer_summary.json` or mirrored `train.log` and extract behavioral_analysis and key metrics.
3) Identify the specific failure mode from behavioral_analysis and metrics. Cross‑check against the “Header evolution: `drone_pp.h`” notes to avoid re‑introducing patterns previously removed.
4) Make minimal, targeted environment code changes to address the failure, aligned with the historical intent captured in Notes.
5) Rebuild bindings and smoke‑test import.
6) Configure the next run using only `autopilot.*` overrides (or `{}`) in `autopilot/proposals/next_config.json`.
7) Record actions/observations/outcomes/next steps in labbook and notes; repeat.

DECISION FRAMEWORK
- Read behavioral_analysis first. Use it to choose an environment‑focused response:
  • diagnostic_grip: Agents aren’t attempting/achieving grip → relax grip gates slightly, refine target hover point, add attempt counters/logs.
  • improve_carrying: Grip works but drops/fails delivery → tune carry stability (mass, drag, grip decay), adjust delivery success gating.
  • fix_stability/high_collisions: Crashes/OOB high → adjust physics constants, collision penalties, spawn spacing, jitter handling.
  • optimize_performance (only after success thresholds met): Improve throughput/observability, not hparams; add logging, keep environment stable.

WHAT YOU CAN CHANGE
- Environment code (primary): e.g., `PufferLib/pufferlib/ocean/drone_pp/drone_pp.h` and adjacent files when necessary.
- Autopilot settings only via overrides file: `autopilot/proposals/next_config.json` keys permitted: 
  • `autopilot.resume_mode` = `fresh` | `continue`
  • `autopilot.resume_from` = `latest` | `best` | explicit checkpoint path
  • `autopilot.save_strategy` = `best` | `latest` | `all`
- Notes and labbook entries.

WHAT YOU CANNOT CHANGE (Hard Rule)
- Do not modify any `train.*`, `env.*`, or `vec.*` hyperparameters in proposals. Under current policy these are off‑limits; the orchestrator ignores them.
- The training script may enforce derived constraints (batch sizing, vec divisibility) for correctness; this is not a policy exception and should not be edited.

ENVIRONMENT DEBUGGING CHECKLIST
1) Identify failure from behavioral_analysis and concrete metrics.
2) Consult `autopilot/journal/notes.md` → “Header evolution: `drone_pp.h` (Sep 11 → Sep 20, 2025)” to understand prior changes and avoid reversions of removed behaviors (e.g., low‑altitude penalty) unless explicitly justified.
3) Locate relevant code in `drone_pp.h` (hover targeting, grip gates, delivery checks, physics constants).
4) Make a minimal, documented change tied to the hypothesis and historical context.
5) Rebuild: `cd PufferLib && NO_TRAIN=1 python3 setup.py build_ext --inplace --force`.
6) Test: `pytest PufferLib/tests/test_env_binding.py -q` (if present) and ensure import works.
7) Document in `runs/<run_id>/notes.txt`: problem → change → expected outcome; reference the specific historical bullet(s) you followed or intentionally deviated from.

SUCCESS METRICS (Define thresholds)
- Baseline environment “working” when, over a stable eval slice:
  • grip_success ≥ 60% and delivery_success ≥ 40% across agents/episodes.
  • end_to_end_success shows an upward trend across 2–3 consecutive runs.
  • OOB/crash resets ≤ 10% of steps; collision‑induced terminations ≤ 5% episodes.
- Stop environment debugging when thresholds are met and metrics are stable; shift to performance/observability improvements only (no hparam tuning).

FAILSAFES
- No behavioral_analysis in summary: fall back to `train.log` inspection; compute basic rates (grips, deliveries, OOB). If absent, add logging counters in env and rerun.
- Build fails: revert the last env patch, rebuild clean, and re‑apply a smaller, testable change.
- Metrics regress for ≥2 runs after a change: revert to previous known‑good env state (use git restore to last good commit) and document rollback.
- When in doubt, prefer smaller env edits and clearer logging over larger refactors.

TECHNICAL DETAILS
- File locations: environment code under `PufferLib/pufferlib/ocean/…` (primary: `drone_pp.h`), configs under `autopilot/configs/`, prompts under `autopilot/prompts/`.
- Build: `cd PufferLib && NO_TRAIN=1 python3 setup.py build_ext --inplace --force` (rebuild native bindings after `.h` changes).
- Tests: `pytest PufferLib/tests/test_env_binding.py -q` when available; otherwise smoke‑import.
- Constraints the script enforces before training:
  • `vec.num_envs % vec.num_workers == 0`.
  • `train.batch_size = env.num_envs × env.num_drones × vec.num_envs × train.bptt_horizon`.
  • `train.minibatch_size = train.batch_size = train.max_minibatch_size`.
- Device: Prefer `mps`; switch to `cpu` only for diagnostics and note slower runtime.
- Run artifacts: `$PUFFER_AUTOPILOT_RUN_DIR`; logs under `autopilot/logs/`.

EXECUTION RULES
- Step 1 is mandatory: Launch {script} immediately from repo root and allow ≥15 minutes. Wait until it completes and capture stdout/stderr. Diagnose early exits before changing configs.
- After the run, write the next overrides as `{}` or only `autopilot.*` keys. Do not propose any other hparam changes.

RECORDKEEPING
- Labbook (`autopilot/journal/labbook.md`): actions, observations (SPS/CPU%), outcome, next step.
- Notes (`autopilot/journal/notes.md`): longer‑term learnings; treat as long‑term memory.
- Drive the training toward better drone behavior (grip → carry → deliver) by understanding what's failing and targeting specific issues.
- Use behavioral analysis to make intelligent decisions about experiment type and focus.
- Honor a strict no‑hyperparameter‑changes policy; use the provided baselines as‑is.

ENVIRONMENT CHANGE TRACKING (DREX Feature)
- Each run captures diffs of environment code (e.g., `env_uncommitted.diff`).
- Summaries may include `environment_comparison` vs the previous run.
- Use these to correlate env changes with outcomes:
  • Grip improves after grip‑gate tweak → keep it.
  • Collision rate spikes after physics change → revert/adjust.
  • Track which files were modified: `drone_pp.h`, `drone_pp.c`, bindings.
Document what changed, why, expected vs actual impact in `runs/<run_id>/notes.txt`.

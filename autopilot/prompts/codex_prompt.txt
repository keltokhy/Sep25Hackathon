Goal:
- Drive the training toward better policy quality (higher `success_rate`, `mean_reward`, lower `collision_rate`) while keeping runs stable and reproducible.

Context:
- Baseline configs live in `autopilot/configs/` (quick vs. full).
- Runtime budget guidance: quick mode (~1 minute) uses the smoke baseline; full mode (~5–6 minutes) uses the high-util baseline (`total_timesteps` ≈ 1e7). When proposing changes, weigh iteration speed against the chance of higher reward.
- `autopilot/proposals/next_config.json` starts empty before each run; fill it **after** the run with overrides for the next iteration. Touch only these keys and respect the safety ranges:
  * `train.learning_rate` (1e-6 – 1.0)
  * `train.ent_coef` (0 – 1)
  * `train.bptt_horizon` (1 – 512)
  * `train.total_timesteps` (1,000 – 1,000,000,000)
  * `train.seed` (0 – 2,147,483,647)
  * `train.update_epochs` (1 – 32)
  * `train.gae_lambda` (0 – 1)
  * `train.gamma` (0 – 0.999999)
  * `train.clip_coef` (0 – 1)
  * `train.vf_clip_coef` (0 – 10)
  * `train.device` (`mps`, `cpu`, or `cuda` for diagnostics)
  * `env.num_envs`, `env.num_drones` (1 – 256)
  * `vec.num_envs`, `vec.num_workers` (1 – 256)
- Constraints:
  * Keep `vec.num_envs` divisible by `vec.num_workers`.
  * Derive batch sizes from your proposal:
    - `train.batch_size = (env.num_envs × env.num_drones × vec.num_envs) × train.bptt_horizon`
    - `train.minibatch_size = train.batch_size = train.max_minibatch_size`
  * On a 28‑core Mac Studio, prefer `vec.num_workers ≤ 28` and `vec.num_envs ∈ {{28, 56, 84}}`. Switching `train.device` to `cpu` is allowed for diagnostics but will slow runs considerably.
- Training artifacts for the active run live in `$PUFFER_AUTOPILOT_RUN_DIR`; structured metrics write to `$PUFFER_AUTOPILOT_SUMMARY` when available.
- Keep the JSON valid; write `{{}}` if you want the next run to reuse the baseline without overrides.

Execution rules:
- Step 1 is mandatory. Your first command must be `bash -lc './{script}'` (or the equivalent via `bash -lc`).
- Do not replace, skip, or defer this command; wait until it completes and capture stdout/stderr.
- If the command fails, report the exit code and diagnose before changing configs.

Example override:
```
{{
  "train": {{"learning_rate": 0.0032, "ent_coef": 0.10, "bptt_horizon": 16,
             "batch_size": 28672, "minibatch_size": 28672, "max_minibatch_size": 28672}},
  "env": {{"num_envs": 4, "num_drones": 8}},
  "vec": {{"num_workers": 28, "num_envs": 56}}
}}
```

Steps:
1. Execute `bash -lc './{script}'` and wait for it to finish.
2. Inspect the results (e.g., tail the fresh log under `autopilot/logs/` or read `$PUFFER_AUTOPILOT_SUMMARY` when it exists).
3. Based on those results, update `autopilot/proposals/next_config.json` with overrides for the **next** run (or `{{}}` if no change).
4. Create or overwrite {notes_path} with a concise status update (for example, `Notes: run completed`). Include brief diagnostics when relevant (CPU/GPU utilisation, SPS, vec/env divisibility, derived batch you used).

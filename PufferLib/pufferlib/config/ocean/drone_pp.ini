[base]
package = ocean
env_name = puffer_drone_pp
policy_name = Policy
rnn_name = Recurrent

[policy]
hidden_size = 256

[rnn]
input_size = 256
hidden_size = 256

[vec]
num_envs = 8

[env]
num_envs = 16 # 16
num_drones = 64 # 64
max_rings = 10

reward_min_dist = 1.6
reward_max_dist = 77.0
dist_decay = 0.5

w_position = 1.13
w_velocity = 0.15
w_stability = 2.0
w_approach = 2.2
w_hover = 1.5

pos_const = 0.63
pos_penalty = 0.03

grip_k_min = 1.0
grip_k_max = 15.0
grip_k_decay = 0.095

box_base_density = 50.0
box_k_growth = 0.02

[train]
adam_beta1 = 0.88382 # 0.9610890980775877
adam_beta2 = 0.94266 # 0.9999260775286266
adam_eps = 0.000010542 # 7.782906079040132e-10
anneal_lr = true
batch_size = auto
bptt_horizon = 64
checkpoint_interval = 200
clip_coef = 0.64632 # 0.05982655642208556
ent_coef = 0.15933 # 0.002465076521024325
gae_lambda = 0.97454 # 0.9641173414828333
gamma = 0.97947 # 0.997472126425902
learning_rate = 0.0063508 # 0.010933756713881205
#learning_rate = 0.005
max_grad_norm = 3.43154 # 1.6317688647793107
max_minibatch_size = 32768
minibatch_size = 32768
prio_alpha = 0.7698 # 0.8968873016577552
prio_beta0 = 0.9593 # 0.8672928227817938
total_timesteps = 200_000_000
update_epochs = 1
#use_rnn = false
vf_clip_coef = 1.20576 # 0.5869845581530236
vf_coef = 4.48159 # 2.1319065538539963
vtrace_c_clip = 1.17604 # 2.714930379733876
vtrace_rho_clip = 2.35241 # 3.8183814893708057

[sweep]
method = Protein
metric = perfect_deliv
goal = maximize
downsample = 0

[sweep.env.w_position]
distribution = uniform
min = 0.0
max = 1.5
mean = 1.13
scale = auto

[sweep.env.w_velocity]
distribution = uniform
min = 0.0
max = 1.5
mean = 0.15
scale = auto

[sweep.env.w_stability]
distribution = uniform
min = 0.0
max = 2.5
mean = 2.0
scale = auto

[sweep.env.w_approach]
distribution = uniform
min = 0.0
max = 2.5
mean = 2.2
scale = auto

[sweep.env.w_hover]
distribution = uniform
min = 0.0
max = 2.0
mean = 1.5
scale = auto

#[sweep.env.reward_min_dist]
#distribution = uniform
#min = 0.1
#max = 5.0
#mean = 1.6
#scale = auto

#[sweep.env.reward_max_dist]
#distribution = uniform
#min = 60.0
#max = 100.0
#mean = 77.0
#scale = auto

#[sweep.env.dist_decay]
#distribution = uniform
#min = 0.01
#max = 0.5
#mean = 0.5
#scale = auto

[sweep.env.pos_const]
distribution = uniform
min = 0.001
max = 1.0
mean = 0.63
scale = auto

[sweep.env.pos_penalty]
distribution = uniform
min = 0.001
max = 0.25
mean = 0.03
scale = auto

#[sweep.env.grip_k_max]
#distribution = uniform
#min = 1.0
#max = 20.0
#mean = 15.0
#scale = auto

#[sweep.env.grip_k_decay]
#distribution = uniform
#min = 0.01
#max = 0.15
#mean = 0.095
#scale = auto

[sweep.env.box_base_density]
distribution = uniform
min = 25.0
max = 100.0
mean = 50.0
scale = auto

[sweep.env.box_k_growth]
distribution = uniform
min = 0.005
max = 0.5
mean = 0.02
scale = auto

#[sweep.train.total_timesteps]
#distribution = log_normal
#min = 2e8
#max = 4e8
#mean = 2e8
#scale = time
